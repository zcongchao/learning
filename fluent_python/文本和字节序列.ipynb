{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3 明确区分了人类可读的文本字符串和原始的字节序列。 隐式地\n",
    "把字节序列转换成 Unicode 文本已成过去。 本章将要讨论 Unicode 字符\n",
    "串、 二进制序列， 以及在二者之间转换时使用的编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“字符串”是个相当简单的概念： 一个字符串是一个字符序列。 问题出\n",
    "在“字符”的定义上。\n",
    "在 2015 年， “字符”的最佳定义是 Unicode 字符。 因此， 从 Python 3 的\n",
    "str 对象中获取的元素是 Unicode 字符， 这相当于从 Python 2 的\n",
    "unicode 对象中获取的元素， 而不是从 Python 2 的 str 对象中获取的原\n",
    "始字节序列。    \n",
    "Unicode 标准把字符的标识和具体的字节表述进行了如下的明确区分。    \n",
    "字符的标识， 即码位， 是 0~1 114 111 的数字（十进制） ， 在\n",
    "Unicode 标准中以 4~6 个十六进制数字表示， 而且加前缀“U+”。 例\n",
    "如， 字母 A 的码位是 U+0041， 欧元符号的码位是 U+20AC， 高音\n",
    "谱号的码位是 U+1D11E。 在 Unicode 6.3 中（这是 Python 3.4 使用的\n",
    "标准） ， 约 10% 的有效码位有对应的字符。     \n",
    "字符的具体表述取决于所用的编码。 编码是在码位和字节序列之间\n",
    "转换时使用的算法。 在 UTF-8 编码中， A（U+0041） 的码位编码成\n",
    "单个字节 \\x41， 而在 UTF-16LE 编码中编码成两个字节\n",
    "\\x41\\x00。 再举个例子， 欧元符号（U+20AC） 在 UTF-8 编码中是\n",
    "三个字节——\\xe2\\x82\\xac， 而在 UTF-16LE 中编码成两个字\n",
    "节： \\xac\\x20。  \n",
    "把码位转换成字节序列的过程是编码； 把字节序列转换成码位的过程是\n",
    "解码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "b'caf\\xc3\\xa9'\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "s = 'café'\n",
    "print(len(s))\n",
    "#使用 UTF-8 把 str 对象编码成 bytes 对象。(即把字符编码为字节)\n",
    "b = s.encode('utf8')\n",
    "print(b)\n",
    "\n",
    "print(len(b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bytes 字面量以 b 开头。字节序列 b 有 5 个字节（在 UTF-8 中， “é”的码位编码成两个字\n",
    "节） 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用 UTF-8 把 bytes 对象解码成 str 对象。(即把字节解码为字符)\n",
    "b.decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想帮助自己记住 .decode() 和 .encode() 的区别， 可\n",
    "以把字节序列想成晦涩难懂的机器磁芯转储， 把 Unicode 字符串想\n",
    "成“人类可读”的文本。 那么， 把字节序列变成人类可读的文本字符\n",
    "串就是解码， 而把字符串变成用于存储或传输的字节序列就是编\n",
    "码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新的二进制序列类型在很多方面与 Python 2 的 str 类型不同。 首先要知\n",
    "道， Python 内置了两种基本的二进制序列类型： Python 3 引入的不可变\n",
    "bytes 类型和 Python 2.6 添加的可变 bytearray 类型。 （Python 2.6 也\n",
    "引入了 bytes 类型， 但那只不过是 str 类型的别名， 与 Python 3 的\n",
    "bytes 类型不同。 ）   \n",
    "bytes 或 bytearray 对象的各个元素是介于 0~255（含） 之间的整\n",
    "数， 而不像 Python 2 的 str 对象那样是单个的字符。 然而， 二进制序列\n",
    "的切片始终是同一类型的二进制序列， 包括长度为 1 的切片， 如示例 4-\n",
    "2 所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe = bytes('café', encoding='utf_8')\n",
    "cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#❷ 各个元素是 range(256) 内的整数。\n",
    "\n",
    "cafe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cafe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'c'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#❸ bytes 对象的切片还是 bytes 对象， 即使是只有一个字节的切片。\n",
    "cafe[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cafe[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'caf\\xc3\\xa9')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe_arr = bytearray(cafe)\n",
    "cafe_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bytearray 对象没有字面量句法， 而是以 bytearray() 和字节序列\n",
    "字面量参数的形式显示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'\\xa9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe_arr[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bytearray 对象的切片还是 bytearray 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cafe_arr[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_bytes[0] 获取的是一个整数， 而 my_bytes[:1] 返回的\n",
    "是一个长度为 1 的 bytes 对象——这一点应该不会让人意\n",
    "外。 s[0] == s[:1] 只对 str 这个序列类型成立。 不过， str 类\n",
    "型的这个行为十分罕见。 对其他各个序列类型来说， s[i] 返回一\n",
    "个元素， 而 s[i:i+1] 返回一个相同类型的序列， 里面是 s[i] 元\n",
    "素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cafe[0]))\n",
    "print(type(cafe[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然二进制序列其实是整数序列， 但是它们的字面量表示法表明其中有\n",
    "ASCII 文本。 因此， 各个字节的值可能会使用下列三种不同的方式显\n",
    "示。\n",
    "可打印的 ASCII 范围内的字节（从空格到 ~） ， 使用 ASCII 字符本\n",
    "身。\n",
    "制表符、 换行符、 回车符和 \\ 对应的字节， 使用转义序列\n",
    "\\t、 \\n、 \\r 和 \\\\。\n",
    "其他字节的值， 使用十六进制转义序列（例如， \\x00 是空字\n",
    "节） 。\n",
    "因此， 在示例 4-2 中， 我们看到的是 b'caf\\xc3\\xa9'： 前 3 个字节\n",
    "b'caf' 在可打印的 ASCII 范围内， 后两个字节则不然"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了格式化方法（format 和 format_map） 和几个处理 Unicode 数据的\n",
    "方法（包括\n",
    "casefold、 isdecimal、 isidentifier、 isnumeric、 isprintable\n",
    "和 encode） 之外，      \n",
    "str 类型的其他方法都支持 bytes 和 bytearray 类\n",
    "型。 这意味着， 我们可以使用熟悉的字符串方法处理二进制序列， 如\n",
    "endswith、 replace、 strip、 translate、 upper 等， 只有少数几个\n",
    "其他方法的参数是 bytes 对象， 而不是 str 对象。 此外， 如果正则表\n",
    "达式编译自二进制序列而不是字符串， re 模块中的正则表达式函数也\n",
    "能处理二进制序列。 Python 3.0~3.4 不能使用 % 运算符处理二进制序\n",
    "列， 但是根据“PEP 461—Adding % formatting to bytes and\n",
    "bytearray”（https://www.python.org/dev/peps/pep-0461/） ， Python 3.5 应该\n",
    "会支持"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二进制序列有个类方法是 str 没有的， 名为 fromhex， 它的作用是解\n",
    "析十六进制数字对（数字对之间的空格是可选的） ， 构建二进制序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1K\\xce\\xa9'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes.fromhex('31 4B CE A9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('h', [-2, -1, 0, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用数组中的原始数据初始化 bytes 对象\n",
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "print(numbers)\n",
    "octets = bytes(numbers)\n",
    "octets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➊ 指定类型代码 h， 创建一个短整数（16 位） 数组。  \n",
    "➋ octets 保存组成 numbers 的字节序列的副本。  \n",
    "➌ 这些是表示那 5 个短整数的 10 个字节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用缓冲类对象创建 bytes 或 bytearray 对象时， 始终复制源对象中\n",
    "的字节序列。 与之相反， memoryview 对象允许在二进制数据结构之间\n",
    "共享内存。 如果想从二进制序列中提取结构化信息， struct 模块是重\n",
    "要的工具。 下一节会使用这个模块处理 bytes 和 memoryview 对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结构体和内存视图  \n",
    "struct 模块提供了一些函数， 把打包的字节序列转换成不同类型字段\n",
    "组成的元组， 还有一些函数用于执行反向转换， 把元组转换成打包的字\n",
    "节序列。 struct 模块能处理 bytes、 bytearray 和 memoryview 对\n",
    "象。  \n",
    "memoryview 类不是用于创建或存储字节序列的， 而\n",
    "是共享内存， 让你访问其他二进制序列、 打包的数组和缓冲中的数据切\n",
    "片， 而无需复制字节序列， 例如 Python Imaging Library（PIL） 就是这\n",
    "样处理图像的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用 memoryview 和 struct 查看一个 GIF 图像的首部\n",
    "import struct\n",
    ">>> fmt = '<3s3sHH' # ➊\n",
    ">>> with open('filter.gif', 'rb') as fp:\n",
    "... img = memoryview(fp.read()) # ➋\n",
    "...\n",
    ">>> header = img[:10] # ➌\n",
    ">>> bytes(header) # ➍\n",
    "b'GIF89a+\\x02\\xe6\\x00'\n",
    ">>> struct.unpack(fmt, header) # ➎\n",
    "(b'GIF', b'89a', 555, 230)\n",
    ">>> del header # ➏\n",
    ">>> del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❶ 结构体的格式： < 是小字节序， 3s3s 是两个 3 字节序列， HH 是两个\n",
    "16 位二进制整数。\n",
    "❷ 使用内存中的文件内容创建一个 memoryview 对象……   \n",
    "❸ ……然后使用它的切片再创建一个 memoryview 对象； 这里不会复\n",
    "制字节序列。    \n",
    "❹ 转换成字节序列， 这只是为了显示； 这里复制了 10 字节。  \n",
    "❺ 拆包 memoryview 对象， 得到一个元组， 包含类型、 版本、 宽度和\n",
    "高度。   \n",
    "❻ 删除引用， 释放 memoryview 实例所占的内存。  \n",
    "注意， memoryview 对象的切片是一个新 memoryview 对象， 而且不会\n",
    "复制字节序列。 [ 本书的技术审校之一 Leonardo Rochael 指出， 如果使\n",
    "用 mmap 模块把图像打开为内存映射文件， 那么会复制少量字节。 本书\n",
    "不会讨论 mmap， 如果你经常读取和修改二进制文件， 可以阅读“mmap\n",
    "—Memory-mapped file\n",
    "support”（https://docs.python.org/3/library/mmap.html） 来进一步学习。 ]\n",
    "本书不会深入介绍 memoryview 和 struct 模块， 如果要处理二进制数\n",
    "据， 可以阅读它们的文档： “Built-in Types » Memory\n",
    "Views”（https://docs.python.org/3/library/stdtypes.html#memory-views）\n",
    "和“struct—Interpret bytes as packed binary\n",
    "data”（https://docs.python.org/3/library/struct.html）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本的编解码器\n",
    "Python 自带了超过 100 种编解码器（codec, encoder/decoder） ， 用于在\n",
    "文本和字节之间相互转换。 每个编解码器都有一个名称， 如 'utf_8'，\n",
    "而且经常有几个别名， 如 'utf8'、 'utf-8' 和 'U8'。 这些名称可以传\n",
    "给 open()、 str.encode()、 bytes.decode() 等函数的 encoding 参\n",
    "数。 示例 4-5 使用 3 个编解码器把相同的文本编码成不同的字节序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1\tb'El Ni\\xf1o'\n",
      "utf_8\tb'El Ni\\xc3\\xb1o'\n",
      "utf_16\tb'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "for codec in ['latin_1', 'utf_8', 'utf_16']:\n",
    "    print(codec, 'El Niño'.encode(codec), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理UnicodeEncodeError\n",
    "多数非 UTF 编解码器只能处理 Unicode 字符的一小部分子集。 把文本转\n",
    "换成字节序列时， 如果目标编码中没有定义某个字符， 那就会抛出\n",
    "UnicodeEncodeError 异常， 除非把 errors 参数传给编码方法或函\n",
    "数， 对错误进行特殊处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S\\xc3\\xa3o Paulo'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = 'São Paulo'\n",
    "city.encode('utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S\\xe3o Paulo'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.encode('iso8859_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0fc0702dd359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cp437'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\encodings\\cp437.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, errors)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "city.encode('cp437') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'So Paulo'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error='ignore' 处理方式悄无声息地跳过无法编码的字符； 这样做通常很是不妥。\n",
    "city.encode('cp437', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S?o Paulo'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#编码时指定 error='replace'， 把无法编码的字符替换成 '?'； 数据损坏了， 但是用户知道出了问题。\n",
    "city.encode('cp437', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S&#227;o Paulo'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#❻ 'xmlcharrefreplace' 把无法编码的字符替换成 XML实体。\n",
    "\n",
    "city.encode('cp437', errors='xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理UnicodeDecodeError      \n",
    "不是每一个字节都包含有效的 ASCII 字符， 也不是每一个字符序列都是\n",
    "有效的 UTF-8 或 UTF-16。 因此， 把二进制序列转换成文本时， 如果假\n",
    "设是这两个编码中的一个， 遇到无法转换的字节序列时会抛出\n",
    "UnicodeDecodeError。\n",
    "另一方面， 很多陈旧的 8 位编码——如 'cp1252'、 'iso8859_1' 和\n",
    "'koi8_r'——能解码任何字节序列流而不抛出错误， 例如随机噪声。\n",
    "因此， 如果程序使用错误的 8 位编码， 解码过程悄无声息， 而得到的是无用输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montréal'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octets = b'Montr\\xe9al'\n",
    "octets.decode('cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-afaa3d3916c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moctets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf_8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "octets.decode('utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montr�al'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octets.decode('utf_8', errors='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 'replace' 错误处理方式， \\xe9 替换成了“ ”（码位是U+FFFD） ， 这是官方指定的 REPLACEMENT CHARACTER（替换字\n",
    "符） ， 表示未知字符。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何找出字节序列的编码\n",
    "如何找出字节序列的编码？ 简单来说， 不能。 必须有人告诉你。\n",
    "有些通信协议和文件格式， 如 HTTP 和 XML， 包含明确指明内容编码\n",
    "的首部。 可以肯定的是， 某些字节流不是 ASCII， 因为其中包含大于\n",
    "127 的字节值， 而且制定 UTF-8 和 UTF-16 的方式也限制了可用的字节\n",
    "序列。 不过即便如此， 我们也不能根据特定的位模式来 100% 确定二进\n",
    "制文件的编码是 ASCII 或 UTF-8。\n",
    "然而， 就像人类语言也有规则和限制一样， 只要假定字节流是人类可读\n",
    "的纯文本， 就可能通过试探和分析找出编码。 例如， 如果 b'\\x00' 字\n",
    "节经常出现， 那么可能是 16 位或 32 位编码， 而不是 8 位编码方案， 因\n",
    "为纯文本中不能包含空字符； 如果字节序列 b'\\x20\\x00' 经常出现，\n",
    "那么可能是 UTF-16LE 编码中的空格字符（U+0020） ， 而不是鲜为人知\n",
    "的 U+2000 EN QUAD 字符——谁知道这是什么呢！\n",
    "统一字符编码侦测包 Chardet（https://pypi.python.org/pypi/chardet） 就是\n",
    "这样工作的， 它能识别所支持的 30 种编码。 Chardet 是一个 Python 库，\n",
    "可以在程序中使用， 不过它也提供了命令行工具 chardetect。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOM： 有用的鬼符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u16 = 'El Niño'.encode('utf_16')\n",
    "u16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " b'\\xff\\xfe'。 这是 BOM， 即字节序标记（byte-order\n",
    "mark） ， 指明编码时使用 Intel CPU 的小字节序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTF-8 的一大优势是， 不管设备使用哪种字节\n",
    "序， 生成的字节序列始终一致， 因此不需要 BOM。 尽管如此， 某些\n",
    "Windows 应用（尤其是 Notepad） 依然会在 UTF-8 编码的文件中添加\n",
    "BOM； 而且， Excel 会根据有没有 BOM 确定文件是不是 UTF-8 编码，\n",
    "否则， 它假设内容使用 Windows 代码页（codepage） 编码。 UTF-8 编码\n",
    "的 U+FEFF 字符是一个三字节序列： b'\\xef\\xbb\\xbf'。 因此， 如果文\n",
    "件以这三个字节开头， 有可能是带有 BOM 的 UTF-8 文件。 然而，\n",
    "Python 不会因为文件以 b'\\xef\\xbb\\xbf' 开头就自动假定它是 UTF-8\n",
    "编码的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为了正确比较而规范化Unicode字符串    \n",
    "因为\n",
    "Unicode 有组合字符（变音符号和附加到前一个字符上的记号， 打\n",
    "印时作为一个整体） ， 所以字符串比较起来很复杂。\n",
    "例如， “café”这个词可以使用两种方式构成， 分别有 4 个和 5 个码位，\n",
    "但是结果完全一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('café', 'café')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U+0301 是 COMBINING ACUTE ACCENT， 加在“e”后面得到“é”。 在\n",
    "Unicode 标准中， 'é' 和 'e\\u0301' 这样的序列叫“标准等价\n",
    "物”（canonical equivalent） ， 应用程序应该把它们视作相同的字符。 但\n",
    "是， Python 看到的是不同的码位序列， 因此判定二者不相等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个问题的解决方案是使用 unicodedata.normalize 函数提供的\n",
    "Unicode 规范化。 这个函数的第一个参数是这 4 个字符串中的一\n",
    "个： 'NFC'、 'NFD'、 'NFKC' 和 'NFKD'。 下面先说明前两个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFC（Normalization Form C） 使用最少的码位构成等价的字符串， 而\n",
    "NFD 把组合字符分解成基字符和单独的组合字符。 这两种规范化方式都\n",
    "能让比较行为符合预期："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "len(normalize('NFC', s1)), len(normalize('NFC', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFD', s1)), len(normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFD', s1) == normalize('NFD', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "西方键盘通常能输出组合字符， 因此用户输入的文本默认是 NFC 形\n",
    "式。 不过， 安全起见， 保存文本之前， 最好使用 normalize('NFC',\n",
    "user_text) 清洗字符串。 NFC 也是 W3C 的“Character Model for the\n",
    "World Wide Web: String Matching and Searching”规范\n",
    "（https://www.w3.org/TR/charmod-norm/） 推荐的规范化形式。      \n",
    "使用 NFC 时， 有些单字符会被规范成另一个单字符。 例如， 电阻的单\n",
    "位欧姆（Ω） 会被规范成希腊字母大写的欧米加。 这两个字符在视觉上\n",
    "是一样的， 但是比较时并不相等， 因此要规范化， 防止出现意外："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('OHM SIGN', 'Ω')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "name(ohm), ohm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GREEK CAPITAL LETTER OMEGA', 'Ω')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm_c = normalize('NFC', ohm)\n",
    "name(ohm_c), ohm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohm == ohm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', ohm) == normalize('NFC', ohm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在另外两个规范化形式（NFKC 和 NFKD） 的首字母缩略词中， 字母 K\n",
    "表示“compatibility”（兼容性） 。 这两种是较严格的规范化形式， 对“兼\n",
    "容字符”有影响。 虽然 Unicode 的目标是为各个字符提供“规范的”码位，\n",
    "但是为了兼容现有的标准， 有些字符会出现多次。 例如， 虽然希腊字母\n",
    "表中有“μ”这个字母（码位是 U+03BC， GREEK SMALL LETTER MU） ，\n",
    "但是 Unicode 还是加入了微符号 'µ'（U+00B5） ， 以便与 latin1 相互\n",
    "转换。 因此， 微符号是一个“兼容字符”。\n",
    "在 NFKC 和 NFKD 形式中， 各个兼容字符会被替换成一个或多个“兼容\n",
    "分解”字符， 即便这样有些格式损失， 但仍是“首选”表述——理想情况\n",
    "下， 格式化是外部标记的职责， 不应该由 Unicode 处理。 下面举个例子。 二分之一 '½'（U+00BD） 经过兼容分解后得到的是三个字符序列\n",
    "'1/2'； 微符号 'µ'（U+00B5） 经过兼容分解后得到的是小写字母\n",
    "'μ'（U+03BC） 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1⁄2'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half = '½'\n",
    "normalize('NFKC', half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#但是把 '4²' 转换成 '42' 就改变原意了\n",
    "four_squared = '4²'\n",
    "normalize('NFKC', four_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('μ', 'μ')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'μ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "micro, micro_kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(956, 956)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ord() 函数是 chr() 函数（对于8位的ASCII字符串）或 unichr() 函数（对于Unicode对象）的配对函数，它以一个字符（长度为1的字符串）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值\n",
    "ord(micro), ord(micro_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GREEK SMALL LETTER MU', 'GREEK SMALL LETTER MU')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(micro), name(micro_kc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 大小写折叠       \n",
    "大小写折叠其实就是把所有文本变成小写， 再做些其他转换。 这个功能\n",
    "由 str.casefold() 方法（Python 3.3 新增） 支持。    \n",
    "对于只包含 latin1 字符的字符串 s， s.casefold() 得到的结果与\n",
    "s.lower() 一样， 唯有一个例外：  德语 Eszett（“sharp s”， ß）\n",
    "会变成“ss”。    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK SMALL LETTER MU'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'μ'\n",
    "name(micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GREEK SMALL LETTER MU'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_cf = micro.casefold()\n",
    "name(micro_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER SHARP S'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett = 'ß'\n",
    "name(eszett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ss'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett_cf = eszett.casefold()\n",
    "eszett_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范化文本匹配实用函数\n",
    "由前文可知， NFC 和 NFD 可以放心使用， 而且能合理比较 Unicode 字\n",
    "符串。 对大多数应用来说， NFC 是最好的规范化形式。 不区分大小写的\n",
    "比较应该使用 str.casefold()。如果要处理多语言文本， 工具箱中应该有 nfc_equal 和\n",
    "fold_equal 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() ==normalize('NFC', str2).casefold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal('A', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "s3 == s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfc_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_equal('A', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极端“规范化”： 去掉变音符号\n",
    "Google 搜索涉及很多技术， 其中一个显然是忽略变音符号（如重音符、\n",
    "下加符等） ， 至少在某些情况下会这么做。 去掉变音符号不是正确的规\n",
    "范化方式， 因为这往往会改变词的意思， 而且可能误判搜索结果。 但是\n",
    "对现实生活却有所帮助： 人们有时很懒， 或者不知道怎么正确使用变音\n",
    "符号， 而且拼写规则会随时间变化， 因此实际语言中的重音经常变来变\n",
    "去。\n",
    "除了搜索， 去掉变音符号还能让 URL更易于阅读， 至少对拉丁语系语\n",
    "言是如此。 下面是维基百科中介绍圣保罗市（São Paulo） 的文章的\n",
    "URL："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://en.wikipedia.org/wiki/S%C3%A3o_Paulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中， “%C3%A3”是 UTF-8 编码“ã”字母（带有波形符的“a”） 转义后得\n",
    "到的结果。 下述形式更友好， 尽管拼写是错误的："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://en.wikipedia.org/wiki/Sao_Paulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想把字符串中的所有变音符号都去掉， 可以使用去掉全部组合记号的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
